{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "class SudokuEnv:\n",
    "    def __init__(self, puzzle):\n",
    "        self.puzzle = puzzle\n",
    "        self.grid = np.array(puzzle)\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.grid = np.array(self.puzzle)\n",
    "        self.done = False\n",
    "        return self.grid\n",
    "\n",
    "    def step(self, action):\n",
    "        row, col, num = action\n",
    "        reward = 0\n",
    "\n",
    "        if self.grid[row, col] != 0:\n",
    "            reward = -1  # Invalid action: cell already filled\n",
    "        elif self._is_valid_move(row, col, num):\n",
    "            self.grid[row, col] = num\n",
    "            reward = 1  # Valid move\n",
    "            if self._is_solved():\n",
    "                reward += 10\n",
    "                self.done = True\n",
    "        else:\n",
    "            reward = -1  # Invalid move\n",
    "\n",
    "        return self.grid, reward, self.done\n",
    "\n",
    "    def _is_valid_move(self, row, col, num):\n",
    "        if num in self.grid[row, :] or num in self.grid[:, col]:\n",
    "            return False\n",
    "        subgrid_x, subgrid_y = 3 * (row // 3), 3 * (col // 3)\n",
    "        if num in self.grid[subgrid_x:subgrid_x+3, subgrid_y:subgrid_y+3]:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def _is_solved(self):\n",
    "        return np.all(self.grid > 0) and self._is_valid_grid()\n",
    "\n",
    "    def _is_valid_grid(self):\n",
    "        for i in range(9):\n",
    "            if len(set(self.grid[i, :])) != 9 or len(set(self.grid[:, i])) != 9:\n",
    "                return False\n",
    "        for x in range(0, 9, 3):\n",
    "            for y in range(0, 9, 3):\n",
    "                subgrid = self.grid[x:x+3, y:y+3].flatten()\n",
    "                if len(set(subgrid)) != 9:\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, learning_rate=0.1, discount_factor=0.9, epsilon=0.1):\n",
    "        self.q_table = {}\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return self._random_action()\n",
    "        state_key = self._state_to_key(state)\n",
    "        if state_key not in self.q_table:\n",
    "            self.q_table[state_key] = {}\n",
    "        return max(self.q_table[state_key], key=self.q_table[state_key].get, default=self._random_action())\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        state_key = self._state_to_key(state)\n",
    "        next_state_key = self._state_to_key(next_state)\n",
    "        if state_key not in self.q_table:\n",
    "            self.q_table[state_key] = {}\n",
    "        if action not in self.q_table[state_key]:\n",
    "            self.q_table[state_key][action] = 0\n",
    "\n",
    "        max_future_q = max(self.q_table.get(next_state_key, {}).values(), default=0)\n",
    "        self.q_table[state_key][action] += self.learning_rate * (reward + self.discount_factor * max_future_q - self.q_table[state_key][action])\n",
    "\n",
    "    def _state_to_key(self, state):\n",
    "        return tuple(state.flatten())\n",
    "\n",
    "    def _random_action(self):\n",
    "        row = random.randint(0, 8)\n",
    "        col = random.randint(0, 8)\n",
    "        num = random.randint(1, 9)\n",
    "        return (row, col, num)\n",
    "\n",
    "    def save(self, filepath):\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(self.q_table, f)\n",
    "\n",
    "    def load(self, filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            self.q_table = pickle.load(f)\n",
    "\n",
    "\n",
    "# Main Training Loop\n",
    "def train_agent(puzzle, episodes, save_path=\"q_table.pkl\"):\n",
    "    env = SudokuEnv(puzzle)\n",
    "    agent = QLearningAgent()\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        step = 0\n",
    "\n",
    "        while not done:\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            agent.update_q_value(state, action, reward, next_state)\n",
    "            state = next_state\n",
    "            step += 1\n",
    "\n",
    "        if env._is_solved():\n",
    "            print(f\"Episode {episode+1}/{episodes} completed in {step} steps. Puzzle solved!\")\n",
    "            print(\"Solved Puzzle:\")\n",
    "            print(env.grid)\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Episode {episode+1}/{episodes} completed. Puzzle not solved.\")\n",
    "\n",
    "    # Save the Q-table after training\n",
    "    agent.save(save_path)\n",
    "    print(f\"Q-table saved to {save_path}\")\n",
    "\n",
    "def solve_puzzle_with_trained_agent(puzzle, q_table_path=\"q_table.pkl\"):\n",
    "    env = SudokuEnv(puzzle)\n",
    "    agent = QLearningAgent()\n",
    "    agent.load(q_table_path)\n",
    "    print(f\"Q-table loaded from {q_table_path}\")\n",
    "\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = agent.get_action(state)\n",
    "        state, _, done = env.step(action)\n",
    "\n",
    "    print(\"Solved Puzzle:\")\n",
    "    print(env.grid)\n",
    "\n",
    "\n",
    "# Example Sudoku Puzzle (0 represents empty cells)\n",
    "sample_puzzle = [\n",
    "    [0, 3, 4, 6, 7, 8, 9, 1, 2],\n",
    "    [6, 7, 2, 1, 9, 5, 3, 4, 8],\n",
    "    [1, 9, 8, 3, 4, 2, 5, 6, 7],\n",
    "    [0, 5, 9, 7, 6, 1, 4, 2, 3],\n",
    "    [4, 2, 6, 8, 5, 3, 7, 9, 1],\n",
    "    [7, 1, 3, 9, 2, 0, 8, 5, 6],\n",
    "    [9, 6, 1, 5, 3, 7, 2, 8, 4],\n",
    "    [2, 0, 7, 4, 1, 9, 6, 3, 5],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "]\n",
    "\n",
    "train_agent(sample_puzzle, episodes=1000, save_path=\"sudoku_q_table.pkl\")\n",
    "solve_puzzle_with_trained_agent(sample_puzzle, q_table_path=\"sudoku_q_table.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
